# Task4

## 整体算法流程

首先使用openpose算法根据原始的摄像头图片识别出人体的骨骼结构

然后使用ST-GCN网络根据人体的骨架结构估计视频中的人物是否发生冲突

 并利用NNI对算法进行进一步的优化

##  openpose算法模型介绍：

人体姿态估计是计算机视觉中一个很基础的问题。从名字的角度来看，可以理解为对“人体”的姿态（关键点，比如头，左手，右脚等）的位置估计。算法使用了“bottom-up”方法，它指先检测图片中所有的人体关键点，然后将这些关键点对应到不同的人物个体。算法流程如下图所示：

![a.png](https://i.loli.net/2021/01/04/ayz4FMZNHfiUsgn.png)

![b.png](https://i.loli.net/2021/01/04/DHnyecEiC5FL8xG.png)

首先将图片输入特征提取网络VGG-19对图片进行特征提取，然后将高维特征输入到后面的主体网络中。整个的技术方案为“two-branch multi-stage CNN”，其中一个分支用于预测打分图confidence maps（S），另外一个分支用于预测Par Affinity Fields（L），也对应着heatmap与vectormap。
 其中，S表示heatmap，j表示要检测的关节数，L表示vectormap，C表示要检测的关节对数。

![c.png](https://i.loli.net/2021/01/04/oaZnXiGqu4yF8vw.png) 

openpose 算法的识别效果图

我们使用了作者所提供的预训练模型来对摄像头所拍摄的影像进行初步的识别

识别的效果如下：

 ![img](https://i.loli.net/2021/01/04/ruYveWH4URn5gAI.png)

我们将录像的每一帧都输入到openpose算法中，最终将得到的骨骼序列的维度为T*N*P*D其中：

T：视频的总帧数

N：视频中的人数

P：openpose能够识别的人体关节点数，我们使用了18点的结构，因此P=18

D：每一个点的坐标维度，openpose用于识别二维坐标，所以D=2表示关键点在图片中的x，y坐标

我们将得到的序列存入npy文件中。

st-gcn算法

通过将图卷积网络扩展到时空图模型，设计用于行为识别的骨骼序列通用表示，称为时空图卷积网络（ST-GCN）。如图 2 所示，该模型是在骨骼图序列上制定的，其中每个节点对应于人体的一个关节。图中存在两种类型的边，即符合关节的自然连接的空间边（spatial edge）和在连续的时间步骤中连接相同关节的时间边（temporal edge）。在此基础上构建多层的时空图卷积，它允许信息沿着空间和时间两个维度进行整合。 

 ![e.jpg](https://i.loli.net/2021/01/04/pXuY5tNxVW8s29P.jpg)

ST-GCN 的输入是图节点的联合坐标向量。这可以被认为是一个基于图像的 CNN 模拟，其中输入由 2D 图像网格上的像素强度矢量形成。对输入数据应用多层的时空图卷积操作，可以生成更高级别的特征图。然后，它将被标准的 SoftMax 分类器分类到相应的动作类别。整个模型用反向传播进行端对端方式的训练。

 ![a.png](https://i.loli.net/2021/01/04/w5pgyYFQXt3DGmv.png)

在本项目中，我们将人体行为分为三类，正常类，危险类和冲突类，并根据标注将图片输入到st-gcn模型中进行训练，最终得到训练号的st-gcn模型，并将该模型在测试集上进行测试，最终得到的混淆矩阵为：

 ![b.png](https://i.loli.net/2021/01/04/mrz3ypf5x7XJnHw.png)

 

 

 

 



 

 

 